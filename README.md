# ğŸ¤– SmartAlly - LLM-Powered Document Data Extractor Chatbot

SmartAlly is a Streamlit-based application that extracts structured data from PDF and HTML documents using OpenAI's GPT-3.5 Turbo for intelligent pattern matching and natural language queries.

## ğŸš€ Quick Start Guide

### For Impatient Users (3 Steps to Get Started)

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure your OpenAI API key
cp .env.example .env
# Edit .env and add: OPENAI_API_KEY=your_api_key_here

# 3. Run the application
streamlit run smartally.py
```

Then:
1. ğŸ“ **Upload** a PDF or HTML document
2. ğŸ’¬ **Ask** "What is the total annual operating expenses for Class A?"
3. âœ… **Get** instant results with page references!

### What Makes SmartAlly Special?

| Feature | Description |
|---------|-------------|
| ğŸ§  **AI-Powered** | Uses GPT-3.5 Turbo for intelligent understanding |
| ğŸ¯ **Precise** | Exact page number references for every extraction |
| ğŸ’¬ **Natural Language** | Ask questions in plain English |
| âš¡ **Fast** | Cached document parsing for quick responses |
| ğŸ”„ **Fallback Mode** | Works even without API key (rule-based) |
| ğŸ”’ **Secure** | API keys stored safely in .env file |

## ğŸ“Š Solution Overview

### System Architecture Flowchart

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERACTION LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Upload Files â”‚ -> â”‚  Ask Query   â”‚ -> â”‚  View Results & Links   â”‚  â”‚
â”‚  â”‚ (PDF/HTML)   â”‚    â”‚  (Natural    â”‚    â”‚  (Values + Page Refs)   â”‚  â”‚
â”‚  â”‚              â”‚    â”‚   Language)  â”‚    â”‚                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DOCUMENT PROCESSING LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PDF Parser   â”‚    â”‚ Table Parser â”‚    â”‚   HTML Parser            â”‚  â”‚
â”‚  â”‚ (PyMuPDF)    â”‚    â”‚ (pdfplumber) â”‚    â”‚   (BeautifulSoup)        â”‚  â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚                          â”‚  â”‚
â”‚  â”‚ â€¢ Text       â”‚    â”‚ â€¢ Tables     â”‚    â”‚ â€¢ Text                   â”‚  â”‚
â”‚  â”‚ â€¢ Pages      â”‚    â”‚ â€¢ Structure  â”‚    â”‚ â€¢ Anchors                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INTELLIGENT EXTRACTION LAYER                       â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    LLM MODE (Recommended)                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  Query Parser  â”‚    ->   â”‚   GPT-3.5 Turbo Extraction     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  (LLM-based)   â”‚         â”‚   â€¢ Understands context        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                â”‚         â”‚   â€¢ Extracts values            â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Identifies   â”‚         â”‚   â€¢ Finds page numbers         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   datapoint    â”‚         â”‚   â€¢ Handles variations         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Recognizes   â”‚         â”‚                                â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   class        â”‚         â”‚                                â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  FALLBACK MODE (Rule-Based)                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  Regex Parser  â”‚    ->   â”‚   Pattern Matching Extraction  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                â”‚         â”‚   â€¢ Predefined patterns        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Pattern      â”‚         â”‚   â€¢ Regex matching             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   matching     â”‚         â”‚   â€¢ Section keywords           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Keywords     â”‚         â”‚                                â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RESPONSE FORMATTING LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Value Format â”‚ -> â”‚ Page Lookup  â”‚ -> â”‚  Hyperlink Generator     â”‚  â”‚
â”‚  â”‚ â€¢ Currency   â”‚    â”‚ â€¢ Context    â”‚    â”‚  â€¢ PDF page links        â”‚  â”‚
â”‚  â”‚ â€¢ Percentage â”‚    â”‚   matching   â”‚    â”‚  â€¢ HTML anchor links     â”‚  â”‚
â”‚  â”‚ â€¢ Text       â”‚    â”‚ â€¢ Location   â”‚    â”‚                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CHAT INTERFACE DISPLAY                          â”‚
â”‚              Shows: Value | Location | Page Number | Link               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Diagram

```
User Query: "What is the total annual operating expenses for Class A?"
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Parse Query (LLM/Regex)            â”‚
â”‚     â†’ Datapoint: TOTAL_ANNUAL_EXPENSES â”‚
â”‚     â†’ Class: Class A                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Load Cached Documents              â”‚
â”‚     â†’ PDF text: pages 1-50             â”‚
â”‚     â†’ Tables: 5 tables extracted       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Extract Data (LLM/Pattern)         â”‚
â”‚     â†’ Search text & tables             â”‚
â”‚     â†’ Find: "1.19%" for Class A        â”‚
â”‚     â†’ Context: "Annual Fund Operating" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Locate Page Number                 â”‚
â”‚     â†’ Match context to page 3          â”‚
â”‚     â†’ Section: "Fees and Expenses"     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Format Response                    â”‚
â”‚     â†’ Value: "1.19%"                   â”‚
â”‚     â†’ Location: "Annual Fund Operating"â”‚
â”‚     â†’ Link: ğŸ“„ Page 3                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â†“
Display in Chat: "The total annual fund operating expenses for Class A is 1.19% 
                  (found in Annual Fund Operating Expenses - ğŸ“„ Page 3)"
```

## Features

- ğŸ“„ **Multi-format Support**: Upload and parse PDF and HTML documents
- ğŸ¤– **Chatbot Interface**: Natural language queries to extract specific data points
- ğŸ§  **LLM-Based Extraction**: Uses GPT-3.5 Turbo for intelligent data extraction and pattern matching
- ğŸ”„ **Fallback Mode**: Automatic fallback to rule-based extraction when API key is not configured
- ğŸ“Š **Table Parsing**: Extracts data from structured tables in PDFs
- ğŸ”— **Smart Source Linking**: Provides hyperlinks with accurate page numbers to the location of extracted data
- ğŸ’¾ **Document Caching**: Efficient parsing with cached results

## Tech Stack

### Technology Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FRONTEND LAYER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        Streamlit 1.28.0                          â”‚   â”‚
â”‚  â”‚  â€¢ Web UI Framework                                              â”‚   â”‚
â”‚  â”‚  â€¢ Chat Interface                                                â”‚   â”‚
â”‚  â”‚  â€¢ File Upload                                                   â”‚   â”‚
â”‚  â”‚  â€¢ Interactive Controls                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI/ML PROCESSING LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    OpenAI GPT-3.5 Turbo                          â”‚   â”‚
â”‚  â”‚  â€¢ Natural Language Understanding                                â”‚   â”‚
â”‚  â”‚  â€¢ Intelligent Data Extraction                                   â”‚   â”‚
â”‚  â”‚  â€¢ Context-Aware Processing                                      â”‚   â”‚
â”‚  â”‚  â€¢ Query Interpretation                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DOCUMENT PROCESSING LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PyMuPDF 1.23.5  â”‚  â”‚ pdfplumber 0.10.3â”‚  â”‚ BeautifulSoup4 4.12.2â”‚  â”‚
â”‚  â”‚  â€¢ PDF text      â”‚  â”‚ â€¢ Table extract  â”‚  â”‚ â€¢ HTML parsing       â”‚  â”‚
â”‚  â”‚  â€¢ Page extract  â”‚  â”‚ â€¢ Structure det. â”‚  â”‚ â€¢ Tag navigation     â”‚  â”‚
â”‚  â”‚  â€¢ Fast parsing  â”‚  â”‚ â€¢ Cell data      â”‚  â”‚ â€¢ Content extract    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA PROCESSING LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Pandas 2.1.1   â”‚  â”‚  Python Regex    â”‚  â”‚  python-dotenv 1.0.0 â”‚  â”‚
â”‚  â”‚  â€¢ DataFrames    â”‚  â”‚  â€¢ Pattern match â”‚  â”‚  â€¢ Env management    â”‚  â”‚
â”‚  â”‚  â€¢ CSV handling  â”‚  â”‚  â€¢ Text extract  â”‚  â”‚  â€¢ API key config    â”‚  â”‚
â”‚  â”‚  â€¢ Data mapping  â”‚  â”‚  â€¢ Validation    â”‚  â”‚  â€¢ Security          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SUPPORT LIBRARIES                               â”‚
â”‚                   lxml 4.9.3  |  openpyxl 3.1.2                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Technologies

- **Python 3.8+**: Main programming language
- **Streamlit 1.28.0**: Interactive web application framework for the chat interface
- **OpenAI GPT-3.5 Turbo**: Large Language Model for intelligent data extraction and query understanding
- **PyMuPDF (fitz) 1.23.5**: Fast and reliable PDF text extraction
- **pdfplumber 0.10.3**: Advanced PDF table extraction with structure detection
- **BeautifulSoup4 4.12.2**: HTML/XML parsing and content extraction
- **pandas 2.1.1**: Data manipulation and CSV handling for datapoint mappings
- **python-dotenv 1.0.0**: Environment variable management for secure API key storage

### Why These Technologies?

| Technology | Purpose | Benefits |
|------------|---------|----------|
| **Streamlit** | Web UI Framework | â€¢ Rapid development<br>â€¢ Built-in chat components<br>â€¢ Easy file handling<br>â€¢ No frontend coding needed |
| **OpenAI GPT-3.5** | AI Extraction | â€¢ Natural language understanding<br>â€¢ Context-aware extraction<br>â€¢ Flexible pattern matching<br>â€¢ High accuracy |
| **PyMuPDF** | PDF Text Extraction | â€¢ Fast performance<br>â€¢ Accurate text extraction<br>â€¢ Page-level organization<br>â€¢ Low memory footprint |
| **pdfplumber** | Table Extraction | â€¢ Preserves table structure<br>â€¢ Cell-level data access<br>â€¢ Handles complex layouts<br>â€¢ Complementary to PyMuPDF |
| **BeautifulSoup4** | HTML Parsing | â€¢ Robust parsing<br>â€¢ Easy navigation<br>â€¢ Handles malformed HTML<br>â€¢ Anchor extraction |
| **pandas** | Data Management | â€¢ Efficient data handling<br>â€¢ CSV integration<br>â€¢ Easy filtering<br>â€¢ Built-in data types |

## Installation

### Prerequisites

- Python 3.8 or higher
- pip (Python package installer)
- OpenAI API key (for LLM features) - Get yours at [OpenAI Platform](https://platform.openai.com/api-keys)

### Step-by-Step Installation

1. **Clone the repository:**
```bash
git clone https://github.com/Tendool/Yitro-Smartally.git
cd Yitro-Smartally
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Configure OpenAI API Key (Required for LLM features):**

   **Option A: Using .env file (Recommended)**
   ```bash
   # Copy the example environment file
   cp .env.example .env
   
   # Edit .env file and add your OpenAI API key
   nano .env  # or use any text editor
   ```
   
   In the `.env` file, replace the placeholder with your actual API key:
   ```bash
   OPENAI_API_KEY=your_actual_api_key_here
   OPENAI_MODEL=gpt-3.5-turbo
   ```

   **Option B: Using environment variable**
   ```bash
   # Linux/Mac
   export OPENAI_API_KEY=your_actual_api_key_here
   
   # Windows (Command Prompt)
   set OPENAI_API_KEY=your_actual_api_key_here
   
   # Windows (PowerShell)
   $env:OPENAI_API_KEY="your_actual_api_key_here"
   ```

   **ğŸ”‘ How to get your OpenAI API Key:**
   - Visit [OpenAI Platform](https://platform.openai.com/api-keys)
   - Sign up or log in to your account
   - Navigate to API Keys section
   - Click "Create new secret key"
   - Copy the key immediately (you won't be able to see it again)
   - Paste it in your `.env` file

   **âš ï¸ Important Security Notes:**
   - Never commit your `.env` file to git (it's already in `.gitignore`)
   - Never share your API key publicly
   - Rotate your key if it's ever exposed
   - Set usage limits in OpenAI dashboard to control costs

4. **Verify installation:**
```bash
python -c "import streamlit; import openai; print('âœ… All dependencies installed!')"
```

**Note**: If you don't configure an API key, the application will automatically use rule-based pattern matching as a fallback (no API key required for basic functionality).

## Usage

### Quick Start

**Linux/Mac:**
```bash
./run.sh
```

**Windows:**
```bash
run.bat
```

Or manually run:
```bash
streamlit run smartally.py
```

The application will open in your default web browser at `http://localhost:8501`.

## How to Use

1. **Upload Documents**: Use the sidebar to upload one or more PDF or HTML files
2. **Configure Extraction Mode**: Toggle between LLM and rule-based extraction (in sidebar settings)
3. **Ask Questions**: Type natural language queries in the chat input at the bottom
4. **View Results**: The extracted value, location, and page number will be displayed with a hyperlink

## Example Queries

With LLM extraction, you can use more natural queries:

- `What is the total annual fund operating expenses for Class A?`
- `Return the net expenses for Class F`
- `Initial investment for Class C Shares`
- `What is the CDSC for Class C?`
- `Redemption Fee for Class Z`
- `Minimum subsequent investment for AIP Class R`

Traditional format also supported:
- `Return only the Data Value of TOTAL_ANNUAL_FUND_OPERATING_EXPENSES for Class A`
- `From the Minimum Investment section, extract the value for Automatic Investment Plans under Subsequent investment for Class R`

## Supported Datapoints

The application supports extracting the following datapoints:

- **TOTAL_ANNUAL_FUND_OPERATING_EXPENSES**: Annual operating expenses by share class
- **NET_EXPENSES**: Net expenses after fee waivers/reimbursements
- **MINIMUM_SUBSEQUENT_INVESTMENT_AIP**: Minimum subsequent investment for Automatic Investment Plans
- **INITIAL_INVESTMENT**: Initial investment amount
- **CDSC**: Contingent Deferred Sales Charge information
- **REDEMPTION_FEE**: Redemption fee details

## Datapoint Mapping

The `datapoint_mapping.csv` file defines the mapping between natural language instructions and extraction rules. You can customize this file to add new datapoints or modify existing ones.

Format:
```csv
Instruction,Datapoint,Class,OutputRule
"Query text",DATAPOINT_NAME,{class},output_format
```

## Output Rules

- **percentage**: Returns values as percentages (e.g., "1.19%")
- **currency**: Returns dollar amounts (e.g., "$1,000")
- **currency_or_text**: Returns currency or text like "No minimum"
- **text**: Returns raw text
- **cdsc_special**: Returns CDSC schedule with years and percentages

## Project Structure

```
Yitro-Smartally/
â”œâ”€â”€ ğŸ“„ smartally.py              # Main application (860 lines)
â”‚   â”œâ”€â”€ Document Parsing Functions
â”‚   â”‚   â”œâ”€â”€ parse_pdf()          # Extract text from PDFs
â”‚   â”‚   â”œâ”€â”€ parse_pdf_tables()   # Extract tables from PDFs
â”‚   â”‚   â””â”€â”€ parse_html()         # Parse HTML documents
â”‚   â”œâ”€â”€ LLM-Based Extraction
â”‚   â”‚   â”œâ”€â”€ extract_datapoint_with_llm()     # GPT-3.5 extraction
â”‚   â”‚   â””â”€â”€ parse_user_prompt_with_llm()     # Query understanding
â”‚   â”œâ”€â”€ Rule-Based Extraction (Fallback)
â”‚   â”‚   â”œâ”€â”€ extract_datapoint()              # Main dispatcher
â”‚   â”‚   â”œâ”€â”€ extract_annual_expenses()        # Extract expenses
â”‚   â”‚   â”œâ”€â”€ extract_net_expenses()           # Extract net expenses
â”‚   â”‚   â”œâ”€â”€ extract_minimum_investment_aip() # Extract AIP minimums
â”‚   â”‚   â”œâ”€â”€ extract_initial_investment()     # Extract initial inv.
â”‚   â”‚   â”œâ”€â”€ extract_cdsc()                   # Extract CDSC
â”‚   â”‚   â””â”€â”€ extract_redemption_fee()         # Extract fees
â”‚   â”œâ”€â”€ Response Generation
â”‚   â”‚   â”œâ”€â”€ chatbot_response()   # Coordinate extraction
â”‚   â”‚   â””â”€â”€ generate_hyperlink() # Create page links
â”‚   â””â”€â”€ Main Application
â”‚       â””â”€â”€ main()                # Streamlit UI
â”‚
â”œâ”€â”€ ğŸ“Š datapoint_mapping.csv     # Datapoint extraction rules
â”‚   â””â”€â”€ Maps: Instructions â†’ Datapoints â†’ Classes â†’ Output Rules
â”‚
â”œâ”€â”€ ğŸ“¦ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ Streamlit 1.28.0        # Web UI framework
â”‚   â”œâ”€â”€ OpenAI >=1.35.0         # GPT-3.5 Turbo API
â”‚   â”œâ”€â”€ PyMuPDF 1.23.5          # PDF text extraction
â”‚   â”œâ”€â”€ pdfplumber 0.10.3       # PDF table extraction
â”‚   â”œâ”€â”€ BeautifulSoup4 4.12.2   # HTML parsing
â”‚   â”œâ”€â”€ pandas 2.1.1            # Data manipulation
â”‚   â””â”€â”€ python-dotenv 1.0.0     # Environment variables
â”‚
â”œâ”€â”€ ğŸ”§ .env.example              # Example environment configuration
â”‚   â”œâ”€â”€ OPENAI_API_KEY          # Your OpenAI API key
â”‚   â””â”€â”€ OPENAI_MODEL            # Model selection (default: gpt-3.5-turbo)
â”‚
â”œâ”€â”€ ğŸ”’ .env                      # Your actual API keys (create this, NOT in git)
â”‚
â”œâ”€â”€ ğŸ§ª test_extraction.py        # Test suite for extraction functions
â”‚
â”œâ”€â”€ ğŸš€ run.sh                    # Quick start script (Linux/Mac)
â”œâ”€â”€ ğŸš€ run.bat                   # Quick start script (Windows)
â”‚
â”œâ”€â”€ ğŸ“– README.md                 # This comprehensive guide
â”œâ”€â”€ ğŸ“– USAGE_GUIDE.md            # Detailed usage instructions
â”œâ”€â”€ ğŸ“– FEATURES.md               # Complete feature list
â”‚
â””â”€â”€ ğŸ“ .gitignore               # Git ignore rules (includes .env)
```

### File Sizes & Statistics

| File | Lines of Code | Purpose |
|------|---------------|---------|
| `smartally.py` | ~860 | Main application logic |
| `test_extraction.py` | ~124 | Test suite |
| `datapoint_mapping.csv` | ~10 | Datapoint definitions |
| **Total Code** | ~984 | Production + Tests |

## Architecture

### Document Parsing Module
- `parse_pdf()`: Extracts text from PDFs using PyMuPDF
- `parse_pdf_tables()`: Extracts tables using pdfplumber
- `parse_html()`: Extracts text and anchors from HTML

### LLM-Based Extraction Module
- `extract_datapoint_with_llm()`: Uses GPT-3.5 Turbo for intelligent extraction
- `parse_user_prompt_with_llm()`: Uses LLM to understand user queries
- Context-aware page number detection

### Legacy Rule-Based Extraction Module (Fallback)
- `extract_datapoint()`: Main extraction dispatcher
- `extract_annual_expenses()`: Extracts annual operating expenses
- `extract_net_expenses()`: Extracts net expenses
- `extract_minimum_investment_aip()`: Extracts AIP investment minimums
- `extract_initial_investment()`: Extracts initial investment amounts
- `extract_cdsc()`: Extracts CDSC schedules
- `extract_redemption_fee()`: Extracts redemption fees

### Response Handler
- `chatbot_response()`: Coordinates extraction and formatting (with LLM/fallback toggle)
- `generate_hyperlink()`: Creates links to source locations

## How It Works

### Complete Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          APPLICATION STARTUP                           â”‚
â”‚  1. Load environment variables (.env file)                             â”‚
â”‚  2. Initialize OpenAI client (if API key present)                      â”‚
â”‚  3. Load datapoint mapping CSV                                         â”‚
â”‚  4. Start Streamlit web server                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DOCUMENT UPLOAD PHASE                          â”‚
â”‚  User Action: Upload PDF/HTML files via sidebar                        â”‚
â”‚                                                                         â”‚
â”‚  System Actions:                                                       â”‚
â”‚  1. Receive uploaded file(s)                                           â”‚
â”‚  2. Detect file type (PDF or HTML)                                     â”‚
â”‚  3. Parse document:                                                    â”‚
â”‚     â€¢ Extract text from each page                                      â”‚
â”‚     â€¢ Extract tables with structure                                    â”‚
â”‚     â€¢ Create page-to-content mapping                                   â”‚
â”‚  4. Cache parsed data in session state                                 â”‚
â”‚  5. Display success confirmation                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          QUERY PROCESSING PHASE                        â”‚
â”‚  User Action: Type question in chat input                              â”‚
â”‚                                                                         â”‚
â”‚  Example: "What is the total annual operating expenses for Class A?"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         EXTRACTION MODE SELECTION                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM MODE (Recommended)   â”‚          â”‚   FALLBACK MODE (Rule-Based)   â”‚
â”‚   Requires: OpenAI API Key â”‚          â”‚   Requires: No API Key         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Parse Query (LLM)  â”‚          â”‚ STEP 1: Parse Query (Regex)    â”‚
â”‚ â€¢ Send query to GPT-3.5    â”‚          â”‚ â€¢ Match against patterns       â”‚
â”‚ â€¢ Identify datapoint       â”‚          â”‚ â€¢ Extract keywords             â”‚
â”‚ â€¢ Extract class name       â”‚          â”‚ â€¢ Identify datapoint type      â”‚
â”‚ â€¢ Understand intent        â”‚          â”‚ â€¢ Find class name              â”‚
â”‚                            â”‚          â”‚                                â”‚
â”‚ Output:                    â”‚          â”‚ Output:                        â”‚
â”‚ â€¢ Datapoint: EXPENSES      â”‚          â”‚ â€¢ Datapoint: EXPENSES          â”‚
â”‚ â€¢ Class: "Class A"         â”‚          â”‚ â€¢ Class: "Class A"             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Extract Data (LLM) â”‚          â”‚ STEP 2: Extract Data (Regex)   â”‚
â”‚ â€¢ Send document text & tab â”‚          â”‚ â€¢ Search text with regex       â”‚
â”‚ â€¢ GPT analyzes content     â”‚          â”‚ â€¢ Match predefined patterns    â”‚
â”‚ â€¢ Finds exact value        â”‚          â”‚ â€¢ Extract from tables          â”‚
â”‚ â€¢ Identifies context words â”‚          â”‚ â€¢ Format according to rule     â”‚
â”‚ â€¢ Returns: value + context â”‚          â”‚                                â”‚
â”‚                            â”‚          â”‚ Output:                        â”‚
â”‚ Output:                    â”‚          â”‚ â€¢ Value: "1.19%"               â”‚
â”‚ â€¢ Value: "1.19%"           â”‚          â”‚ â€¢ Section keywords             â”‚
â”‚ â€¢ Context: "Annual Fund    â”‚          â”‚                                â”‚
â”‚   Operating Expenses"      â”‚          â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Find Page Number   â”‚          â”‚ STEP 3: Find Approximate Page  â”‚
â”‚ â€¢ Match context keywords   â”‚          â”‚ â€¢ Search for section keywords  â”‚
â”‚   to page content          â”‚          â”‚ â€¢ Find first matching page     â”‚
â”‚ â€¢ Identify exact page      â”‚          â”‚ â€¢ Return page number           â”‚
â”‚ â€¢ High accuracy            â”‚          â”‚ â€¢ Lower accuracy               â”‚
â”‚                            â”‚          â”‚                                â”‚
â”‚ Output: Page 3             â”‚          â”‚ Output: Page ~3                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                              â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STEP 4: FORMAT RESPONSE                           â”‚
â”‚  â€¢ Apply output formatting rules (currency, percentage, text)          â”‚
â”‚  â€¢ Generate hyperlink with page number                                 â”‚
â”‚  â€¢ Create user-friendly message                                        â”‚
â”‚                                                                         â”‚
â”‚  Example Output:                                                       â”‚
â”‚  "The total annual fund operating expenses for Class A is 1.19%        â”‚
â”‚   (found in Annual Fund Operating Expenses - ğŸ“„ Page 3)"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STEP 5: DISPLAY IN CHAT                           â”‚
â”‚  â€¢ Add message to chat history                                         â”‚
â”‚  â€¢ Render in Streamlit interface                                       â”‚
â”‚  â€¢ User can click page link for verification                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LLM Mode (Recommended)

**When to use:** When OpenAI API key is configured (best accuracy and flexibility)

1. **User Query Submission**
   - User types natural language question
   - Example: "What is the total annual operating expenses for Class A?"

2. **LLM Query Analysis**
   - Query sent to GPT-3.5 Turbo
   - LLM identifies:
     - Datapoint: `TOTAL_ANNUAL_FUND_OPERATING_EXPENSES`
     - Class: `Class A`
   - Understands variations and context

3. **LLM Data Extraction**
   - Document text and tables sent to GPT-3.5
   - LLM intelligently:
     - Searches through content
     - Understands table structure
     - Extracts exact value: `1.19%`
     - Identifies context: "Annual Fund Operating Expenses"

4. **Context-Aware Page Location**
   - System matches context keywords to page content
   - Finds exact page number where value appears
   - High accuracy page detection

5. **Result Display**
   - Formatted response with value, location, and clickable page link
   - User can verify by clicking the link

**Benefits:**
- âœ… Natural language queries
- âœ… Handles document variations
- âœ… High accuracy
- âœ… Context understanding
- âœ… Flexible extraction

### Fallback Mode (Rule-Based)

**When to use:** When OpenAI API key is not configured (automatic fallback)

1. **User Query Submission**
   - User types query
   - Can use structured format or natural language

2. **Pattern-Based Query Parsing**
   - Regex patterns match against query
   - Extracts datapoint name and class
   - Uses predefined keyword matching

3. **Rule-Based Data Extraction**
   - Searches text using regex patterns
   - Matches against known structures
   - Extracts from tables using position
   - Applies formatting rules

4. **Approximate Page Location**
   - Searches for section keywords
   - Finds page with matching content
   - Less accurate than LLM mode

5. **Result Display**
   - Formatted response with value and location
   - Approximate page number if found

**Benefits:**
- âœ… No API key required
- âœ… Fast execution
- âœ… Works offline
- âœ… Predictable behavior
- âš ï¸ Less flexible than LLM mode

### Comparison Table

| Feature | LLM Mode | Fallback Mode |
|---------|----------|---------------|
| **API Key Required** | âœ… Yes | âŒ No |
| **Natural Language** | âœ… Full support | âš ï¸ Limited |
| **Accuracy** | â­â­â­â­â­ High | â­â­â­ Medium |
| **Page Detection** | â­â­â­â­â­ Precise | â­â­â­ Approximate |
| **Handle Variations** | âœ… Yes | âš ï¸ Limited |
| **Speed** | âš ï¸ 2-5 seconds | âœ… < 1 second |
| **Cost** | ğŸ’° API usage | âœ… Free |
| **Offline Mode** | âŒ No | âœ… Yes |

## Development

### Adding New Datapoints

1. Add a new row to `datapoint_mapping.csv`
2. Implement an extraction function in `smartally.py`
3. Add the function to the dispatcher in `extract_datapoint()`

### Testing

Upload sample PDF or HTML files containing fund prospectus data and test various queries to ensure accurate extraction.

## ğŸ”§ Troubleshooting

### Common Issues and Solutions

#### 1. "OpenAI API Key not found" warning

**Problem:** Application shows a warning about missing API key.

**Solution:**
```bash
# Create .env file from example
cp .env.example .env

# Edit .env and add your API key
nano .env  # or use any text editor

# Make sure the file contains:
OPENAI_API_KEY=sk-proj-your-actual-key-here
```

#### 2. OpenAI API errors or timeouts

**Problem:** "API request failed", "Client.__init__() got an unexpected keyword argument" or timeout errors.

**Solutions:**

**If you see "Client.__init__() got an unexpected keyword argument 'proxies'":**
```bash
# This is a version compatibility issue. Install compatible versions:
pip install 'openai>=1.35.0' 'httpx>=0.24.0,<0.28.0'

# Or use these specific versions that are known to work:
pip install openai==1.35.0 httpx==0.27.0
```

**Other API issues:**
- Check your API key is valid at [OpenAI Platform](https://platform.openai.com/api-keys)
- Verify you have API credits available
- Check your internet connection
- The app will automatically fall back to rule-based mode if API fails

**Note:** The application will work in fallback mode even if the OpenAI library has issues. Only LLM features require the API.

#### 3. Document parsing fails

**Problem:** Uploaded document doesn't parse correctly.

**Solutions:**
- Ensure file is a valid PDF or HTML
- Check file isn't password-protected or corrupted
- Try a different file format (PDF vs HTML)
- Check file size (very large files may take time)

#### 4. No results found for query

**Problem:** System returns "Value not found" or "0".

**Solutions:**
- Check your query includes the share class (e.g., "Class A")
- Verify the datapoint exists in the document
- Try rephrasing your question
- Use more specific queries
- Check the document contains the expected data

#### 5. Installation errors

**Problem:** `pip install` fails or module not found errors.

**Solutions:**
```bash
# Upgrade pip first
python3 -m pip install --upgrade pip

# Install with user flag if permission denied
pip install --user -r requirements.txt

# Use virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

#### 6. Streamlit won't start

**Problem:** `streamlit run` command not found.

**Solutions:**
```bash
# Install streamlit explicitly
pip install streamlit

# Or run with python module
python3 -m streamlit run smartally.py

# Check if streamlit is in PATH
which streamlit  # Linux/Mac
where streamlit  # Windows
```

### Performance Tips

1. **First query may be slow** - Subsequent queries are faster due to caching
2. **Use LLM mode for best accuracy** - But fallback mode is faster
3. **Upload multiple documents** - They're all parsed and cached
4. **Clear cache if issues** - Restart the app to clear session state

### Getting Help

- ğŸ“– Read the [USAGE_GUIDE.md](USAGE_GUIDE.md) for detailed instructions
- ğŸ› Report issues on [GitHub Issues](https://github.com/Tendool/Yitro-Smartally/issues)
- ğŸ’¡ Check [FEATURES.md](FEATURES.md) for complete feature list

## ğŸ’¡ Tips & Best Practices

### For Best Results

1. **Use Specific Queries**
   - âœ… Good: "What is the total annual operating expenses for Class A?"
   - âŒ Avoid: "Show me expenses"

2. **Include Share Class**
   - Always mention the specific class (Class A, Class I, etc.)
   - Be consistent with naming (use "Class A" not "A Class")

3. **Verify Results**
   - Click the page link to verify the extracted value
   - Cross-check with the original document

4. **Document Quality**
   - Use clear, well-formatted PDFs for best results
   - Scanned PDFs with OCR work but may have lower accuracy

5. **API Key Management**
   - Never commit .env file to git
   - Rotate keys periodically
   - Set usage limits in OpenAI dashboard
   - Monitor your API usage and costs

### Cost Optimization

- **Use Fallback Mode** for testing and development (free)
- **Use LLM Mode** for production and accuracy (costs API credits)
- **Cache documents** to avoid re-parsing (automatic)
- **Batch similar queries** together for efficiency

## License

This project is provided as-is for educational and development purposes.

## Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.